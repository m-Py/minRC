
#' Anticlustering
#'
#' Create sets of elements (anticlusters) that are as similar as
#' possible to each other, by maximizing the heterogeneity within
#' anticlusters.  Implements anticlustering algorithms as described in
#' Papenberg and Klau (2019).
#'
#' @param x The data input. Can be one of two structures: (1) A data
#'     matrix where rows correspond to elements and columns correspond
#'     to features (a single numeric feature can be passed as a
#'     vector). (2) An N x N matrix dissimilarity matrix; can be an
#'     object of class \code{dist} (e.g., returned by
#'     \code{\link{dist}} or \code{\link{as.dist}}) or a \code{matrix}
#'     where the entries of the upper and lower triangular matrix
#'     represent the pairwise dissimilarities.
#' @param K How many anticlusters should be created. Alternatively: A
#'     vector of length \code{nrow(x)} describing how elements are
#'     assigned to anticlusters before the optimization starts.
#' @param objective The objective to be maximized. The option
#'     "distance" (default) maximizes the cluster editing objective
#'     function; the option "variance" maximizes the k-means objective
#'     function. See Details.
#' @param method One of "exchange" (default) or "ilp". See Details.
#' @param preclustering Boolean. Should a preclustering be conducted
#'     before anticlusters are created? Defaults to \code{FALSE}. See
#'     Details.
#' @param categories A vector, data.frame or matrix representing one
#'     or several categorical constraints. See Details.
#'
#' @return A vector of length N that assigns a group (i.e, a number
#'     between 1 and \code{K}) to each input element.
#'
#' @importFrom Matrix sparseMatrix
#' @importFrom stats as.dist dist
#'
#' @export
#'
#' @author
#' Martin Papenberg \email{martin.papenberg@@hhu.de}
#'
#' @details
#'
#' This function is used to solve »K anticlustering«. That is, K
#' groups are created in such a way that all groups are as similar as
#' possible. In the standard case, groups of equal size are
#' returned. Adjust the \code{K} argument to create groups of
#' different size.
#'
#' Set similarity is assessed using one of two objective functions:
#'
#' - k-means `variance` objective, setting \code{objective = "variance"}
#'
#' - cluster editing `distance` objective, setting \code{objective =
#'   "distance"}
#'
#' The k-means objective measures the variance within
#' anticlusters---that is, the sum of the squared distances between
#' each element and its cluster center (see
#' \code{\link{variance_objective}}). The cluster editing objective
#' measures the sum of pairwise distances within anticlusters (see
#' \code{\link{distance_objective}}). Anticluster editing is also known 
#' as the »maximum diverse grouping problem«. Maximizing either of these
#' anticlustering objectives will partition the data set into similar groups. 
#' Minimization of the same objectives would lead to a clustering, i.e., groups 
#' with high within-group similarity but between-group dissimilarity 
#' Balanced clustering is possible using the function
#' \code{\link{balanced_clustering}}.
#'
#' If the argument \code{x} is a feature matrix and the option
#' \code{objective = "distance"} is used, the Euclidean distance is
#' computed as the basic unit of the anticluster editing objective. If
#' a different measure of dissimilarity is preferred, you may pass a
#' self-generated dissimiliarity matrix via the argument \code{x}.
#'
#' \strong{Heuristic anticlustering}
#'
#' By default, a heuristic method is employed for anticlustering: the
#' exchange method (\code{method = "exchange"}). Building on an
#' initial assignment of elements to anticlusters, elements are
#' sequentially swapped between anticlusters in such a way that each
#' swap improves set similarity by the largest amount that is
#' possible. In the default case, elements are randomly assigned to
#' anticlusters before the exchange procedure starts; however, it is
#' also possible to explicitly specify the initial assignment using
#' the argument \code{K} (in this case, \code{K} has length
#' \code{nrow(x)}). The exchange procedure is repeated for each
#' element. Because each possible swap is investigated for each
#' element, the total number of exchanges grows quadratically with
#' input size, rendering the exchange method unsuitable for large
#' N. Setting \code{preclustering = TRUE} will limit the legal
#' exchange partners to very similar elements, resulting in improved
#' run time while preserving a rather good solution. This option is
#' recommended for larger N. For very large N, check out the function
#' \code{\link{fast_anticlustering}} that was specifically implemented
#' for large data sets.
#'
#' \strong{Exact anticlustering}
#'
#' An optimal anticluster editing objective can be found via integer
#' linear programming (the integer linear program implemented here can
#' be found in Papenberg & Klau, 2019, Appendix B). To this end, set
#' \code{method = "ilp"}. To obtain an optimal solution, the open
#' source GNU linear programming kit (available from
#' https://www.gnu.org/software/glpk/glpk.html) and the R package
#' \code{Rglpk} must be installed. The optimal solution is retrieved
#' by setting \code{objective = "distance"}, \code{method = "ilp"} and
#' \code{preclustering = FALSE}. Use this combination of arguments
#' only for small problem sizes.
#'
#' To relax the optimality requirement, it is possible to set the
#' argument \code{preclustering = TRUE}. In this case, the anticluster
#' editing objective is still optimized using integer linear
#' programming, but a preprocessing forbids very similar elements to
#' be assigned to the same anticluster. Thus, before the
#' anticlustering objective is optimized, a cluster analysis
#' identifies small groups of similar elements (pairs if \code{K = 2},
#' triplets if \code{K = 3}, and so forth). The preclustering reduces
#' the size of the solution space, making the ILP approach applicable
#' for larger problem instances. With preclustering, optimality is no
#' longer guaranteed, but the solution is usually optimal or very
#' close to optimal.
#'
#' The variance criterion cannot be optimized to optimality using
#' integer linear programming. However, it is possible to employ the
#' function \code{\link{generate_partitions}} to obtain optimal
#' solutions for small problem instances.
#' 
#' \strong{Categorical constraints}
#'
#' The argument \code{categories} may induce categorical constraints.
#' The grouping variables indicated by \code{categories} will be
#' balanced out across anticlusters. Currently, this functionality is
#' only available in combination with the exchange method, but not
#' with the exact ILP approach. 
#' 
#' \strong{Custom objective function}
#' 
#' It is possible to pass a \code{function} to the argument
#' \code{objective}. See \code{\link{mean_sd_obj}} for an example. If
#' \code{objective} is a function, the exchange method assigns
#' elements to anticlusters in such a way that the return value of the
#' custom function is maximized (hence, the function should return
#' larger values when anticlusters are more similar). It has to take
#' two arguments: the first being the clustering assignment, the
#' second being the data argument. That is, the argument \code{x} will
#' be passed down to the user-defined function as second argument,
#' however \strong{only after} \code{\link{as.matrix}} has been called
#' on it. This implies that in the function body, columns of the data
#' set cannot be accessed using \code{data.frame} operations such as
#' \code{$}. This implies that data of class \code{dist} will be 
#' converted to matrix as well.
#' 
#' 
#' @seealso
#'
#' \code{\link{fast_anticlustering}}
#'
#' \code{\link{variance_objective}}
#'
#' \code{\link{distance_objective}}
#'
#'
#' @examples
#'
#' # Optimize the cluster editing (distance) criterion
#' anticlusters <- anticlustering(
#'   schaper2019[, 3:6],
#'   K = 3,
#'   categories = schaper2019$room
#' )
#' # Compare feature means by anticluster
#' by(schaper2019[, 3:6], anticlusters, function(x) round(colMeans(x), 2))
#' # Compare standard deviations by anticluster
#' by(schaper2019[, 3:6], anticlusters, function(x) round(apply(x, 2, sd), 2))
#' # check that the "room" is balanced across anticlusters:
#' table(anticlusters, schaper2019$room)
#' 
#' # You can try to improve the solution using the old output as 
#' # the new K argument:
#' new_anticlusters <- anticlustering(
#'   schaper2019[, 3:6],
#'   K = anticlusters,
#'   categories = schaper2019$room
#' )
#'
#' 
#' ## Use preclustering and variance (k-means) criterion on large data set
#' N <- 1000
#' K = 2
#' lds <- data.frame(f1 = rnorm(N), f2 = rnorm(N))
#' ac <- anticlustering(
#'   lds, 
#'   K = K,
#'   objective = "variance",
#'   preclustering = TRUE
#' )
#' 
#' # The following is equivalent to setting `preclustering = TRUE`:
#' cl <- balanced_clustering(lds, K = N / K)
#' ac <- anticlustering(
#'   lds, 
#'   K = K,
#'   objective = "variance",
#'   categories = cl
#' )
#'
#' @references
#'
#' Grötschel, M., & Wakabayashi, Y. (1989). A cutting plane algorithm
#' for a clustering problem. Mathematical Programming, 45, 59-96.
#'
#' Papenberg, M., & Klau, G. W. (2019, October 30). Using anticlustering to partition 
#' data sets into equivalent parts https://doi.org/10.31234/osf.io/3razc
#'
#' Späth, H. (1986). Anticlustering: Maximizing the variance criterion.
#' Control and Cybernetics, 15, 213-218.
#'

anticlustering <- function(x, K, objective = "distance", method = "exchange",
                           preclustering = FALSE, categories = NULL) {

  ## Get data into required format
  input_validation_anticlustering(x, K, objective, method, preclustering, categories)
  data <- to_matrix(x)

  ## Exact method using ILP
  if (method == "ilp") {
    return(exact_anticlustering(
      data,
      K,
      preclustering)
    )
  }
  
  # Preclustering and categorical constraints are both processed in the
  # variable `categories` after this step:
  categories <- get_categorical_constraints(data, K, preclustering, categories)
  
  if (class(objective) == "function") {
    # most generic exchange method, deals with any objective function
    return(exchange_method(data, K, objective, categories))
  }

  # Redirect to specialized fast exchange methods for distance and 
  # variance objectives
  if (objective == "variance") {
    return(fast_anticlustering(data, K, Inf, categories))
  } else if (objective == "distance") {
    return(fast_exchange_dist(data, K, categories))
  }
}

# Function that processes input and returns the data set that the
# optimization is conducted on as matrix (for exchange method)
# Returned matrix either represents distances or features.
to_matrix <- function(data) {
  if (!is_distance_matrix(data)) {
    data <- as.matrix(data)
    return(data)
  }
  as.matrix(as.dist(data))
}

# Determines if preclustering constraints or categorical constraints
# are present. Returns a grouping vector if one or both constraints 
# have been passed, or NULL if none is required
get_categorical_constraints <- function(data, K, preclustering, categories) {
  if (preclustering == TRUE) {
    if (length(K) > 1) {
      K <- length(unique(K))
    }
    N <- nrow(data)
    matches <- matching(data, p = K, match_within = categories, sort_output = FALSE)
    # deal with NA in matches
    return(replace_na_by_index(matches))
  }
  if (argument_exists(categories)) {
    return(merge_into_one_variable(categories))
  }
  NULL
}

replace_na_by_index <- function(matches) {
  na_matches <- is.na(matches)
  NAs <- sum(na_matches) 
  if (NAs == 0) {
    return(matches)
  }
  max_group <- max(matches, na.rm = TRUE)
  matches[na_matches] <- max_group + 1:NAs 
  matches
}
